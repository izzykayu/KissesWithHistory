{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isabelmetzger/.local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of labeled 1\n",
      "651\n",
      "number of rows\n",
      "1403\n",
      "percentage of target\n",
      "46.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&amp; Kopp, B. T. IFN-gamma stimulates autophagy-m...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>TRN0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pulmonary inflammation induced by Pseudomonas ...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>TRN1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>These circulating EV-RNA levels have been foun...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>TRN2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The company's lead product candidates include ...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>TRN3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Its lead product candidate comprises larotrect...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>TRN4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  sentiment  label    id\n",
       "0  & Kopp, B. T. IFN-gamma stimulates autophagy-m...          8      1  TRN0\n",
       "1  Pulmonary inflammation induced by Pseudomonas ...          8      1  TRN1\n",
       "2  These circulating EV-RNA levels have been foun...          8      0  TRN2\n",
       "3  The company's lead product candidates include ...          8      1  TRN3\n",
       "4  Its lead product candidate comprises larotrect...          8      0  TRN4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## lstm simple zerostart no feature engineering\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "# importing train and test files\n",
    "train = pd.read_csv(\"/Users/isabelmetzger/PycharmProjects/ClinicalScorecard/train_set.txt\", \n",
    "                  '\\t')\n",
    "train = train.rename(columns = {\n",
    "#     \"sentence\": \"text\",\n",
    "    \"polarity\": \"label\"})\n",
    "train['id'] = ['TRN' + str(idx) for idx in range(len(train))]\n",
    "test = pd.read_csv('/Users/isabelmetzger/PycharmProjects/ClinicalScorecard/test_set.txt', '\\t')\n",
    "test = test.rename(columns = {\n",
    "# \"sentence\": \"text\", \n",
    "                              \"polarity\": \"label\"})\n",
    "test['id'] = ['TST' + str(idx) for idx in range(len(test))]\n",
    "\n",
    "\n",
    "train = train.drop_duplicates(subset=None, keep='first', inplace=False)  \n",
    "train = train.dropna()\n",
    "\n",
    "def get_binary_target1_stats(train):\n",
    "    print('number of labeled 1')\n",
    "    print(train.label.sum())\n",
    "    print('number of rows')\n",
    "    print(train.shape[0])\n",
    "    print('percentage of target')\n",
    "    print(round(train.label.sum()/train.shape[0]*100))\n",
    "    \n",
    "get_binary_target1_stats(train)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of labeled 1\n",
      "258\n",
      "number of rows\n",
      "552\n",
      "percentage of target\n",
      "47.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In contrast, mice treated with lipid nanoparti...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>TST0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The company's lead SARM candidate is the enobo...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>TST1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Swappable DNA tiles makes for world's smallest...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>TST2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>For cells infected with CHIKV E1:226VT percent...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>TST3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We have previously observed the up-regulation ...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>TST4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  sentiment  label    id\n",
       "0  In contrast, mice treated with lipid nanoparti...          8      0  TST0\n",
       "1  The company's lead SARM candidate is the enobo...          8      0  TST1\n",
       "2  Swappable DNA tiles makes for world's smallest...          8      0  TST2\n",
       "3  For cells infected with CHIKV E1:226VT percent...          8      0  TST3\n",
       "4  We have previously observed the up-regulation ...          8      1  TST4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentence classifier \n",
    "test = test.drop_duplicates(subset=None, keep='first', inplace=False)\n",
    "test = test.dropna()\n",
    "get_binary_target1_stats(test)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [1]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "X = train.sentence\n",
    "y = train.label.values\n",
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(y)\n",
    "Y = y.reshape(-1,1)\n",
    "print(Y[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K backend imported!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The company's lead product candidates include PTG-100, an oral alpha-4-beta-7 integrin- antagonist that is in Phase II b clinical trial for the treatment of ulcerative colitis, as well as for treating chronic pouchitis, a gastrointestinal (GI) condition that occurs in post-surgical inflammatory bowel disease (IBD) patients; PTG-200, an oral interleukin-23 receptor antagonist, which is in Phase I clinical trial for the treatment of IBD; and PTG-300, an injectable hepcidin mimetic, which has completed Phase I study for use in the treatment of beta-thalassemia, as well as for treating other diseases, such as hereditary hemochromatosis, polycythemia vera, siderophilic infections, and liver fibrosis.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def binary_accuracy(y_true, y_pred):\n",
    "    return K.mean(K.equal(y_true, K.round(y_pred)))\n",
    "\n",
    "\n",
    "def categorical_accuracy(y_true, y_pred):\n",
    "    return K.mean(K.equal(K.argmax(y_true, axis=-1),\n",
    "                          K.argmax(y_pred, axis=-1)))\n",
    "\n",
    "\n",
    "def sparse_categorical_accuracy(y_true, y_pred):\n",
    "    return K.mean(K.equal(K.max(y_true, axis=-1),\n",
    "                          K.cast(K.argmax(y_pred, axis=-1), K.floatx())))\n",
    "\n",
    "\n",
    "def top_k_categorical_accuracy(y_true, y_pred, k=5):\n",
    "    return K.mean(K.in_top_k(y_pred, K.argmax(y_true, axis=-1), k))\n",
    "\n",
    "\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    return K.mean(K.square(y_pred - y_true))\n",
    "\n",
    "\n",
    "def mean_absolute_error(y_true, y_pred):\n",
    "    return K.mean(K.abs(y_pred - y_true))\n",
    "\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    diff = K.abs((y_true - y_pred) / K.clip(K.abs(y_true),\n",
    "                                            K.epsilon(),\n",
    "                                            None))\n",
    "    return 100. * K.mean(diff)\n",
    "\n",
    "\n",
    "def mean_squared_logarithmic_error(y_true, y_pred):\n",
    "    first_log = K.log(K.clip(y_pred, K.epsilon(), None) + 1.)\n",
    "    second_log = K.log(K.clip(y_true, K.epsilon(), None) + 1.)\n",
    "    return K.mean(K.square(first_log - second_log))\n",
    "\n",
    "\n",
    "def hinge(y_true, y_pred):\n",
    "    return K.mean(K.maximum(1. - y_true * y_pred, 0.))\n",
    "\n",
    "\n",
    "def squared_hinge(y_true, y_pred):\n",
    "    return K.mean(K.square(K.maximum(1. - y_true * y_pred, 0.)))\n",
    "\n",
    "\n",
    "def categorical_crossentropy(y_true, y_pred):\n",
    "    return K.mean(K.categorical_crossentropy(y_pred, y_true))\n",
    "\n",
    "\n",
    "def sparse_categorical_crossentropy(y_true, y_pred):\n",
    "    return K.mean(K.sparse_categorical_crossentropy(y_pred, y_true))\n",
    "\n",
    "\n",
    "def binary_crossentropy(y_true, y_pred):\n",
    "    return K.mean(K.binary_crossentropy(y_pred, y_true))\n",
    "\n",
    "\n",
    "def kullback_leibler_divergence(y_true, y_pred):\n",
    "    y_true = K.clip(y_true, K.epsilon(), 1)\n",
    "    y_pred = K.clip(y_pred, K.epsilon(), 1)\n",
    "    return K.mean(K.sum(y_true * K.log(y_true / y_pred), axis=-1))\n",
    "\n",
    "\n",
    "def poisson(y_true, y_pred):\n",
    "    return K.mean(y_pred - y_true * K.log(y_pred + K.epsilon()))\n",
    "\n",
    "\n",
    "def cosine_proximity(y_true, y_pred):\n",
    "    y_true = K.l2_normalize(y_true, axis=-1)\n",
    "    y_pred = K.l2_normalize(y_pred, axis=-1)\n",
    "    return -K.mean(y_true * y_pred)\n",
    "\n",
    "def matthews_correlation(y_true, y_pred):\n",
    "    \"\"\"Matthews correlation metric.\n",
    "    It is only computed as a batch-wise average, not globally.\n",
    "    Computes the Matthews correlation coefficient measure for quality\n",
    "    of binary classification problems.\n",
    "    \"\"\"\n",
    "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "    y_pred_neg = 1 - y_pred_pos\n",
    "\n",
    "    y_pos = K.round(K.clip(y_true, 0, 1))\n",
    "    y_neg = 1 - y_pos\n",
    "\n",
    "    tp = K.sum(y_pos * y_pred_pos)\n",
    "    tn = K.sum(y_neg * y_pred_neg)\n",
    "\n",
    "    fp = K.sum(y_neg * y_pred_pos)\n",
    "    fn = K.sum(y_pos * y_pred_neg)\n",
    "\n",
    "    numerator = (tp * tn - fp * fn)\n",
    "    denominator = K.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
    "\n",
    "    return numerator / (denominator + K.epsilon())\n",
    "\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "    Only computes a batch-wise average of precision.\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "    Only computes a batch-wise average of recall.\n",
    "    Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def fbeta_score(y_true, y_pred, beta=1):\n",
    "    \"\"\"Computes the F score.\n",
    "    The F score is the weighted harmonic mean of precision and recall.\n",
    "    Here it is only computed as a batch-wise average, not globally.\n",
    "    This is useful for multi-label classification, where input samples can be\n",
    "    classified as sets of labels. By only using accuracy (precision) a model\n",
    "    would achieve a perfect score by simply assigning every class to every\n",
    "    input. In order to avoid this, a metric should penalize incorrect class\n",
    "    assignments as well (recall). The F-beta score (ranged from 0.0 to 1.0)\n",
    "    computes this, as a weighted mean of the proportion of correct class\n",
    "    assignments vs. the proportion of incorrect class assignments.\n",
    "    With beta = 1, this is equivalent to a F-measure. With beta < 1, assigning\n",
    "    correct classes becomes more important, and with beta > 1 the metric is\n",
    "    instead weighted towards penalizing incorrect class assignments.\n",
    "    \"\"\"\n",
    "    if beta < 0:\n",
    "        raise ValueError('The lowest choosable beta is zero (only precision).')\n",
    "\n",
    "    # If there are no true positives, fix the F score at 0 like sklearn.\n",
    "    if K.sum(K.round(K.clip(y_true, 0, 1))) == 0:\n",
    "        return 0\n",
    "\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    bb = beta ** 2\n",
    "    fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())\n",
    "    return fbeta_score\n",
    "\n",
    "\n",
    "def fmeasure(y_true, y_pred):\n",
    "    \"\"\"Computes the f-measure, the harmonic mean of precision and recall.\n",
    "    Here it is only computed as a batch-wise average, not globally.\n",
    "    \"\"\"\n",
    "    return fbeta_score(y_true, y_pred, beta=1)\n",
    "\n",
    "\n",
    "# aliases\n",
    "mse = MSE = mean_squared_error\n",
    "mae = MAE = mean_absolute_error\n",
    "mape = MAPE = mean_absolute_percentage_error\n",
    "msle = MSLE = mean_squared_logarithmic_error\n",
    "cosine = cosine_proximity\n",
    "fscore = f1score = fmeasure\n",
    "print(\"K backend imported!\")\n",
    "\n",
    "# le = LabelEncoder()\n",
    "# Y = le.fit_transform(y)\n",
    "# Y_train = y.reshape(-1,1)\n",
    "\n",
    "t = train['sentence'][3]  \n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isabelmetzger/anaconda3/lib/python3.6/site-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.20.3 when using version 0.21.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/isabelmetzger/anaconda3/lib/python3.6/site-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.20.3 when using version 0.21.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[\"company's\", 1, 3, 'ENTITY'],\n",
       " ['PTG-100', 7, 8, 'ENTITY'],\n",
       " ['oral', 10, 11, 'ENTITY'],\n",
       " ['antagonist', 13, 14, 'ENTITY'],\n",
       " ['Phase II b', 17, 20, 'ENTITY'],\n",
       " ['clinical trial', 20, 22, 'ENTITY'],\n",
       " ['treatment', 24, 25, 'ENTITY'],\n",
       " ['ulcerative colitis', 26, 28, 'ENTITY'],\n",
       " ['treating', 33, 34, 'ENTITY'],\n",
       " ['chronic pouchitis', 34, 36, 'ENTITY'],\n",
       " ['gastrointestinal (', 38, 40, 'ENTITY'],\n",
       " ['GI', 40, 41, 'ENTITY'],\n",
       " ['condition', 42, 43, 'ENTITY'],\n",
       " ['post-surgical', 46, 47, 'ENTITY'],\n",
       " ['inflammatory bowel disease', 47, 50, 'ENTITY'],\n",
       " ['IBD', 51, 52, 'ENTITY'],\n",
       " ['patients', 53, 54, 'ENTITY'],\n",
       " ['PTG-200', 55, 56, 'ENTITY'],\n",
       " ['oral interleukin-23 receptor antagonist', 58, 62, 'ENTITY'],\n",
       " ['Phase I', 66, 68, 'ENTITY'],\n",
       " ['treatment', 72, 73, 'ENTITY'],\n",
       " ['IBD', 74, 75, 'ENTITY'],\n",
       " ['PTG-300', 77, 78, 'ENTITY'],\n",
       " ['injectable', 80, 81, 'ENTITY'],\n",
       " ['hepcidin', 81, 82, 'ENTITY'],\n",
       " ['mimetic', 82, 83, 'ENTITY'],\n",
       " ['Phase I study', 87, 90, 'ENTITY'],\n",
       " ['treatment', 94, 95, 'ENTITY'],\n",
       " ['beta-thalassemia', 96, 97, 'ENTITY'],\n",
       " ['treating', 102, 103, 'ENTITY'],\n",
       " ['diseases', 104, 105, 'ENTITY'],\n",
       " ['hereditary hemochromatosis', 108, 110, 'ENTITY'],\n",
       " ['polycythemia vera', 111, 113, 'ENTITY'],\n",
       " ['siderophilic infections', 114, 116, 'ENTITY'],\n",
       " ['liver fibrosis', 118, 120, 'ENTITY']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "from scispacy.abbreviation import AbbreviationDetector\n",
    "from scispacy.umls_linking import UmlsEntityLinker\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "nlp = spacy.load('en_core_sci_md')\n",
    "abbreviation_pipe = AbbreviationDetector(nlp)\n",
    "nlp.add_pipe(abbreviation_pipe)\n",
    "linker = UmlsEntityLinker()\n",
    "nlp.add_pipe(linker)\n",
    "  \n",
    "#     \"\"\"\n",
    "#     return doc.to_json()\n",
    "\n",
    "def get_list_ents(doc):\n",
    "    return [[ent.text, ent.start, ent.end, ent.label_] for ent in doc.ents]\n",
    "\n",
    "\n",
    "doc = nlp(t)\n",
    "get_list_ents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['PTG-100', 7, 8, 'DNA'], ['oral interleukin-23 receptor', 58, 61, 'PROTEIN']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import en_ner_jnlpba_md\n",
    "import en_ner_craft_md\n",
    "import en_ner_bionlp13cg_md\n",
    "import en_ner_bc5cdr_md\n",
    "import en_core_web_lg\n",
    "\n",
    "jnlpba = en_ner_jnlpba_md.load()\n",
    "\n",
    "get_list_ents(jnlpba(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['antagonist', 13, 14, 'CHEBI'],\n",
       " ['interleukin-23 receptor', 59, 61, 'GGP'],\n",
       " ['antagonist', 61, 62, 'CHEBI'],\n",
       " ['PTG-300', 77, 78, 'CL'],\n",
       " ['hepcidin', 81, 82, 'GGP']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "craft = en_ner_craft_md.load()\n",
    "get_list_ents(craft(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['PTG-100', 7, 8, 'CHEMICAL'],\n",
       " ['ulcerative colitis', 26, 28, 'DISEASE'],\n",
       " ['pouchitis', 35, 36, 'DISEASE'],\n",
       " ['gastrointestinal (GI) condition that occurs in post-surgical inflammatory bowel disease',\n",
       "  38,\n",
       "  50,\n",
       "  'DISEASE'],\n",
       " ['IBD', 51, 52, 'DISEASE'],\n",
       " ['IBD', 74, 75, 'DISEASE'],\n",
       " ['beta-thalassemia', 96, 97, 'DISEASE'],\n",
       " ['hereditary hemochromatosis', 108, 110, 'DISEASE'],\n",
       " ['polycythemia vera', 111, 113, 'DISEASE'],\n",
       " ['siderophilic infections', 114, 116, 'DISEASE'],\n",
       " ['liver fibrosis', 118, 120, 'DISEASE']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bc5cdr = en_ner_bc5cdr_md.load()\n",
    "get_list_ents(bc5cdr(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma_</th>\n",
       "      <th>pos_</th>\n",
       "      <th>tag_</th>\n",
       "      <th>dep_</th>\n",
       "      <th>shape_</th>\n",
       "      <th>is_alpha</th>\n",
       "      <th>is_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>det</td>\n",
       "      <td>Xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>company</td>\n",
       "      <td>company</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>poss</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'s</td>\n",
       "      <td>'s</td>\n",
       "      <td>PART</td>\n",
       "      <td>POS</td>\n",
       "      <td>case</td>\n",
       "      <td>'x</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lead</td>\n",
       "      <td>lead</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>compound</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>product</td>\n",
       "      <td>product</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>compound</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>candidates</td>\n",
       "      <td>candidate</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>include</td>\n",
       "      <td>include</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBP</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PTG-100</td>\n",
       "      <td>ptg-100</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>dobj</td>\n",
       "      <td>XXX-ddd</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,</td>\n",
       "      <td>punct</td>\n",
       "      <td>,</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>an</td>\n",
       "      <td>an</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>det</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>oral</td>\n",
       "      <td>oral</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>amod</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>alpha-4-beta-7</td>\n",
       "      <td>alpha-4-beta-7</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>amod</td>\n",
       "      <td>xxxx-d-xxxx-d</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>integrin-</td>\n",
       "      <td>integrin-</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>compound</td>\n",
       "      <td>xxxx-</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>antagonist</td>\n",
       "      <td>antagonist</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>appos</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>that</td>\n",
       "      <td>that</td>\n",
       "      <td>PRON</td>\n",
       "      <td>WDT</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              text          lemma_   pos_ tag_      dep_         shape_  \\\n",
       "0              The             the    DET   DT       det            Xxx   \n",
       "1          company         company   NOUN   NN      poss           xxxx   \n",
       "2               's              's   PART  POS      case             'x   \n",
       "3             lead            lead   NOUN   NN  compound           xxxx   \n",
       "4          product         product   NOUN   NN  compound           xxxx   \n",
       "5       candidates       candidate   NOUN  NNS     nsubj           xxxx   \n",
       "6          include         include   VERB  VBP      ROOT           xxxx   \n",
       "7          PTG-100         ptg-100   NOUN   NN      dobj        XXX-ddd   \n",
       "8                ,               ,  PUNCT    ,     punct              ,   \n",
       "9               an              an    DET   DT       det             xx   \n",
       "10            oral            oral    ADJ   JJ      amod           xxxx   \n",
       "11  alpha-4-beta-7  alpha-4-beta-7   NOUN   NN      amod  xxxx-d-xxxx-d   \n",
       "12       integrin-       integrin-   NOUN   NN  compound          xxxx-   \n",
       "13      antagonist      antagonist   NOUN   NN     appos           xxxx   \n",
       "14            that            that   PRON  WDT     nsubj           xxxx   \n",
       "\n",
       "    is_alpha  is_stop  \n",
       "0       True     True  \n",
       "1       True    False  \n",
       "2      False     True  \n",
       "3       True    False  \n",
       "4       True    False  \n",
       "5       True    False  \n",
       "6       True    False  \n",
       "7      False    False  \n",
       "8      False    False  \n",
       "9       True     True  \n",
       "10      True    False  \n",
       "11     False    False  \n",
       "12     False    False  \n",
       "13      True    False  \n",
       "14      True     True  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linguistic_features_for_embeddings = [[token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "            token.shape_, token.is_alpha, token.is_stop] for token in doc]\n",
    "pd.DataFrame(linguistic_features_for_embeddings).head(15).rename(columns={0:'text', 1: 'lemma_', 2: 'pos_', 3: 'tag_', 4: \n",
    "                                                                         'dep_', 5: 'shape_', 6: 'is_alpha', 7: 'is_stop'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================\n",
      "Phase II b\n",
      "===================\n",
      "CUI: C1706096, Name: Phase II B Trial\n",
      "Definition: A clinical research protocol generally referred to as a well-controlled and pivotal trial that aims to prove the mechanism of action of the new intervention in question. A pivotal study will generally be well-controlled, randomized, of adequate size, and whenever possible, double-blind.\n",
      "TUI(s): T062\n",
      "Aliases: (total: 6): \n",
      "\t 2B, Trial Phase 2B, Trial Phase 2B, Phase IIb Trial, Trial Phase IIB, PHASE IIB TRIAL\n",
      "CUI: C0282460, Name: Phase 2 Clinical Trials\n",
      "Definition: Works about studies that are usually controlled to assess the effectiveness and dosage (if appropriate) of diagnostic, therapeutic, or prophylactic drugs, devices, or techniques. These studies are performed on several hundred volunteers, including a limited number of patients with the target disease or disorder, and last about two years. This concept includes phase II studies conducted in both the U.S. and in other countries.\n",
      "TUI(s): T062\n",
      "Aliases (abbreviated, total: 22): \n",
      "\t 2 clinical phase trials, clinical trials phase 2, phase ii clinical trial, clinical trial phase II, Phase II Clinical Trial, Clinical Trials, Phase II, clinical ii phase trials, phase ii clinical trials, phase ii study, Phase II Study\n",
      "CUI: C0205390, Name: Phase\n",
      "Definition: A distinguishable part, a stage in a series of events or in a process of development, e.g. any of the varying aspects or stages in course of a disease; a fraction of a cycle.\n",
      "TUI(s): T079\n",
      "Aliases: (total: 7): \n",
      "\t Phase, Phase, Phase, phase, Phased, Stage, Phase (attribute)\n",
      "===================\n",
      "===================\n",
      "beta-thalassemia\n",
      "===================\n",
      "CUI: C0005283, Name: beta Thalassemia\n",
      "Definition: A disorder characterized by reduced synthesis of the beta chains of hemoglobin. There is retardation of hemoglobin A synthesis in the heterozygous form (thalassemia minor), which is asymptomatic, while in the homozygous form (thalassemia major, Cooley's anemia, Mediterranean anemia, erythroblastic anemia), which can result in severe complications and even death, hemoglobin A synthesis is absent.\n",
      "TUI(s): T047\n",
      "Aliases (abbreviated, total: 45): \n",
      "\t beta Thalassemia, beta Thalassemia, beta Thalassemia, beta Thalassemia, beta Thalassemia, thalassemia beta, Beta thalassemia, Beta thalassemia, Beta thalassemia, BETA-THALASSEMIA\n",
      "CUI: C4274391, Name: Dominant beta-thalassemia\n",
      "Definition: Dominant beta-thalassemia is a form of beta-thalassemia resulting in moderate to severe anemia. Prevalence of this form is not known. Presents with moderate to severe anemia, jaundice and splenomegaly. Rare mutations in the beta-globin HBB gene result in synthesis of extremely unstable beta-globin variants which precipitate in erythroid precursors causing ineffective erythropoiesis.\n",
      "TUI(s): T047\n",
      "Aliases: (total: 5): \n",
      "\t BETA-THALASSEMIA, DOMINANT, Dominant beta-thalassaemia, Inclusion body beta-thalassemia, Inclusion body beta-thalassaemia, Dominant beta-thalassemia (disorder)\n",
      "CUI: C0002312, Name: alpha-Thalassemia\n",
      "Definition: A disorder characterized by reduced synthesis of the alpha chains of hemoglobin. The severity of this condition can vary from mild anemia to death, depending on the number of genes deleted.\n",
      "TUI(s): T047\n",
      "Aliases (abbreviated, total: 37): \n",
      "\t alpha-Thalassemia, alpha-Thalassemia, thalassemia alpha, Thalassemia, Alpha, Alpha thalassemia, alpha-thalassemia, ALPHA-THALASSEMIA, ALPHA-THALASSEMIA, ALPHA-THALASSEMIA, alpha thalassemia\n",
      "CUI: C0271990, Name: delta-Thalassemia\n",
      "Definition: A hereditary disorder characterized by reduced or absent DELTA-GLOBIN thus effecting the level of HEMOGLOBIN A2, a minor component of adult hemoglobin monitored in the diagnosis of BETA-THALASSEMIA.\n",
      "TUI(s): T047\n",
      "Aliases (abbreviated, total: 12): \n",
      "\t delta-Thalassemia, Delta thalassemia, DELTA-THALASSEMIA, delta Thalassemia, delta Thalassemia, delta Thalassemia, delta Thalassemia, NOS, Delta thalassaemia, delta-Thalassemias, delta Thalassaemia\n"
     ]
    }
   ],
   "source": [
    "print(\"===================\")\n",
    "print(doc.ents[4])\n",
    "print(\"===================\")\n",
    "entity_phase_II_b = doc.ents[4]\n",
    "for umls_ent in entity_phase_II_b._.umls_ents:\n",
    "\n",
    "    print(linker.umls.cui_to_entity[umls_ent[0]])\n",
    "print(\"===================\")\n",
    "print(\"===================\")\n",
    "print(doc.ents[28])\n",
    "print(\"===================\")\n",
    "beta_thalassemia = doc.ents[28]\n",
    "for umls_ent in beta_thalassemia._.umls_ents:\n",
    "    print(linker.umls.cui_to_entity[umls_ent[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[GI, 40, 41, gastrointestinal],\n",
       " [IBD, 74, 75, inflammatory bowel disease],\n",
       " [IBD, 51, 52, inflammatory bowel disease]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[abbrev, abbrev.start, abbrev.end, abbrev._.long_form] for abbrev in doc._.abbreviations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[\"company's\", []],\n",
       " ['PTG-100',\n",
       "  [('C3812281', 0.9009826183319092), ('C1414627', 0.9009826183319092)]],\n",
       " ['oral',\n",
       "  [('C0442027', 1.0),\n",
       "   ('C1527415', 1.0),\n",
       "   ('C1272919', 1.0),\n",
       "   ('C0226896', 1.0)]],\n",
       " ['antagonist',\n",
       "  [('C0231491', 1.0),\n",
       "   ('C0016411', 0.8194425106048584),\n",
       "   ('C0036753', 0.8177525401115417),\n",
       "   ('C0019593', 0.803914487361908),\n",
       "   ('C0597668', 0.8030994534492493)]],\n",
       " ['Phase II b',\n",
       "  [('C1706096', 0.8509665131568909),\n",
       "   ('C0282460', 0.7450801730155945),\n",
       "   ('C0205390', 0.7105843424797058)]],\n",
       " ['clinical trial',\n",
       "  [('C1096775', 1.0),\n",
       "   ('C0008976', 1.0),\n",
       "   ('C1552009', 1.0),\n",
       "   ('C2983596', 0.8558200597763062),\n",
       "   ('C2827983', 0.8512393236160278)]],\n",
       " ['treatment',\n",
       "  [('C3538994', 1.0),\n",
       "   ('C3161471', 1.0),\n",
       "   ('C0039798', 1.0),\n",
       "   ('C3887704', 1.0),\n",
       "   ('C0087111', 1.0)]],\n",
       " ['ulcerative colitis',\n",
       "  [('C0009324', 0.9999999403953552),\n",
       "   ('C4053902', 0.8694170117378235),\n",
       "   ('C0041582', 0.8100262880325317)]],\n",
       " ['treating', [('C1522326', 1.0), ('C2985688', 0.7695987820625305)]],\n",
       " ['chronic pouchitis', []],\n",
       " ['gastrointestinal (',\n",
       "  [('C0521362', 0.8217094540596008),\n",
       "   ('C0596601', 0.763201117515564),\n",
       "   ('C1333802', 0.7367568016052246),\n",
       "   ('C2987127', 0.7356742024421692),\n",
       "   ('C0687713', 0.7318880558013916)]],\n",
       " ['GI',\n",
       "  [('C0521362', 1.0),\n",
       "   ('C0596601', 0.9287967681884766),\n",
       "   ('C1333802', 0.8966148495674133),\n",
       "   ('C2987127', 0.8952974081039429),\n",
       "   ('C0687713', 0.8906895518302917)]],\n",
       " ['condition',\n",
       "  [('C0348080', 1.0),\n",
       "   ('C1705253', 1.0),\n",
       "   ('C0012634', 1.0),\n",
       "   ('C1701901', 0.8715108633041382),\n",
       "   ('C1963686', 0.8715108633041382)]],\n",
       " ['post-surgical',\n",
       "  [('C0179410', 0.8914327621459961), ('C0085124', 0.7896255254745483)]],\n",
       " ['inflammatory bowel disease',\n",
       "  [('C0021390', 1.0), ('C0010346', 0.9820541739463806)]],\n",
       " ['IBD', [('C0021390', 1.0), ('C0010346', 0.9820541739463806)]],\n",
       " ['patients',\n",
       "  [('C0030705', 0.9999999403953552),\n",
       "   ('C0025360', 0.8272134065628052),\n",
       "   ('C0017313', 0.7958329916000366),\n",
       "   ('C1550655', 0.7685564756393433),\n",
       "   ('C1705908', 0.7685564756393433)]],\n",
       " ['PTG-200', []],\n",
       " ['oral interleukin-23 receptor antagonist',\n",
       "  [('C3812686', 0.8423478007316589),\n",
       "   ('C1416402', 0.8423478007316589),\n",
       "   ('C1704264', 0.8349181413650513),\n",
       "   ('C1504688', 0.7939453721046448),\n",
       "   ('C1149393', 0.7681185007095337)]],\n",
       " ['Phase I',\n",
       "  [('C0205390', 0.8506150841712952),\n",
       "   ('C0920321', 0.8042625784873962),\n",
       "   ('C1155818', 0.7701516151428223),\n",
       "   ('C0080129', 0.7143722176551819)]],\n",
       " ['treatment',\n",
       "  [('C3538994', 1.0),\n",
       "   ('C3161471', 1.0),\n",
       "   ('C0039798', 1.0),\n",
       "   ('C3887704', 1.0),\n",
       "   ('C0087111', 1.0)]],\n",
       " ['IBD', [('C0021390', 1.0), ('C0010346', 0.9820541739463806)]],\n",
       " ['PTG-300', []],\n",
       " ['injectable',\n",
       "  [('C0086466', 0.9999999403953552),\n",
       "   ('C1272883', 0.9999999403953552),\n",
       "   ('C1272936', 0.9999999403953552),\n",
       "   ('C1828121', 0.9999999403953552),\n",
       "   ('C3641623', 0.8317238092422485)]],\n",
       " ['hepcidin', [('C0966897', 1.0), ('C1423607', 1.0)]],\n",
       " ['mimetic',\n",
       "  [('C1553857', 0.7060409784317017),\n",
       "   ('C2698268', 0.7060409784317017),\n",
       "   ('C0066554', 0.7060409784317017)]],\n",
       " ['Phase I study',\n",
       "  [('C0920321', 1.0),\n",
       "   ('C0282460', 0.8904679417610168),\n",
       "   ('C0282461', 0.8835915327072144),\n",
       "   ('C0282462', 0.8786568641662598),\n",
       "   ('C1880229', 0.7449774742126465)]],\n",
       " ['treatment',\n",
       "  [('C3538994', 1.0),\n",
       "   ('C3161471', 1.0),\n",
       "   ('C0039798', 1.0),\n",
       "   ('C3887704', 1.0),\n",
       "   ('C0087111', 1.0)]],\n",
       " ['beta-thalassemia',\n",
       "  [('C0005283', 1.0),\n",
       "   ('C4274391', 0.8631060719490051),\n",
       "   ('C0002312', 0.8128412365913391),\n",
       "   ('C0271990', 0.7942267656326294)]],\n",
       " ['treating', [('C1522326', 1.0), ('C2985688', 0.7695987820625305)]],\n",
       " ['diseases',\n",
       "  [('C0012634', 1.0),\n",
       "   ('C0029896', 0.9021040201187134),\n",
       "   ('C1145628', 0.8737022280693054),\n",
       "   ('C0007350', 0.8572169542312622),\n",
       "   ('C0005940', 0.8538870811462402)]],\n",
       " ['hereditary hemochromatosis',\n",
       "  [('C0392514', 0.9999999403953552),\n",
       "   ('C0534369', 0.9372931122779846),\n",
       "   ('C1853733', 0.8124542832374573),\n",
       "   ('C1384665', 0.7986471056938171),\n",
       "   ('C0018995', 0.7986471056938171)]],\n",
       " ['polycythemia vera',\n",
       "  [('C0032463', 0.9999998807907104),\n",
       "   ('C0032461', 0.9072173833847046),\n",
       "   ('C1514197', 0.8722280859947205),\n",
       "   ('C1824675', 0.8335208892822266),\n",
       "   ('C0913852', 0.8335208892822266)]],\n",
       " ['siderophilic infections', []],\n",
       " ['liver fibrosis',\n",
       "  [('C0239946', 1.0),\n",
       "   ('C4285457', 0.7999469041824341),\n",
       "   ('C0016059', 0.7999469041824341),\n",
       "   ('C0009714', 0.7847037315368652),\n",
       "   ('C1333965', 0.7787793278694153)]]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[ent.text, ent._.umls_ents] for ent in doc.ents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "sci_md = spacy.load(\"en_core_sci_md\")\n",
    "def clean_text(text):\n",
    "    doc = sci_md(text)\n",
    "    text_out = \" \".join([token.text.lower() for token in doc])\n",
    "    return text_out\n",
    "\n",
    "train['text'] = train['sentence'].apply(lambda x: clean_text(str(x)))\n",
    "test['text'] = test['sentence'].apply(lambda x: clean_text(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1403,) (552,)\n",
      "31     by a pilot study with small population , il-17...\n",
      "27     results : the spect/ct and mri were found to h...\n",
      "446    ( c ) aberrant cdx2 expression in squamoid mor...\n",
      "700    for needs assessment of these specific tumors ...\n",
      "204    the companyâ ’s product candidates include x35...\n",
      "Name: text, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "257"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train.text\n",
    "test_X = test.text\n",
    "print(X.shape, test_X.shape) \n",
    "X_train = train.text\n",
    "y_train = train.label.values\n",
    "X_test = test.text\n",
    "y_test = test.label.values\n",
    "le = LabelEncoder()\n",
    "Y_train = le.fit_transform(y_train)\n",
    "print(X_train.sample(5))\n",
    "le = LabelEncoder()\n",
    "Y_test = le.fit_transform(y_test)\n",
    "train['Ntokens'] = train['text'].apply(lambda x: len(x.split(' ')))\n",
    "test['Ntokens'] = test['text'].apply(lambda x: len(x.split(' ')))\n",
    "\n",
    "np.max(train['Ntokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequences Matrix Made!\n"
     ]
    }
   ],
   "source": [
    "max_words = 3500\n",
    "max_len = 3500\n",
    "tok = Tokenizer(num_words=max_words)\n",
    "tok.fit_on_texts(X_train)\n",
    "sequences = tok.texts_to_sequences(X_train)\n",
    "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)\n",
    "print(\"Sequences Matrix Made!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 3500)              0         \n",
      "_________________________________________________________________\n",
      "embedding_4 (Embedding)      (None, 3500, 100)         350000    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 64)                42240     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 409,137\n",
      "Trainable params: 409,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def RNN():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,100,input_length=max_len)(inputs)\n",
    "    layer = LSTM(64)(layer)\n",
    "    layer = Dense(256,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.2)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model\n",
    "model = RNN()\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy', precision, recall, fmeasure])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1122 samples, validate on 281 samples\n",
      "Epoch 1/24\n",
      "1122/1122 [==============================] - 97s 86ms/step - loss: 0.6779 - acc: 0.6230 - precision: 0.6025 - recall: 0.4948 - fmeasure: 0.4760 - val_loss: 0.6479 - val_acc: 0.5836 - val_precision: 0.4555 - val_recall: 0.0790 - val_fmeasure: 0.1329\n",
      "Epoch 2/24\n",
      "1122/1122 [==============================] - 100s 89ms/step - loss: 0.3779 - acc: 0.8431 - precision: 0.8493 - recall: 0.8330 - fmeasure: 0.8247 - val_loss: 0.5598 - val_acc: 0.7367 - val_precision: 0.7011 - val_recall: 0.6655 - val_fmeasure: 0.6796\n",
      "Epoch 3/24\n",
      "1122/1122 [==============================] - 95s 85ms/step - loss: 0.1978 - acc: 0.9269 - precision: 0.9401 - recall: 0.9073 - fmeasure: 0.9155 - val_loss: 0.6317 - val_acc: 0.7189 - val_precision: 0.6946 - val_recall: 0.6189 - val_fmeasure: 0.6483\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ac1e97f60>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sequences_matrix,Y_train,batch_size=32,epochs=24,\n",
    "          validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "552/552 [==============================] - 7s 13ms/step\n",
      "Val set\n",
      "  Loss: 0.571\n",
      "  Accuracy: 0.772\n"
     ]
    }
   ],
   "source": [
    "test_sequences = tok.texts_to_sequences(X_test)\n",
    "test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)\n",
    "accr = model.evaluate(test_sequences_matrix,Y_test)\n",
    "\n",
    "print('Val set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1], accr[2], accr[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SECOND MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "print('loading embeddings vectors')\n",
    "def get_coefs(word,*arr): \n",
    "    return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "embeddings_index = dict(get_coefs(*o.split(' '))\n",
    "        for o in open('/embeddings/glove.840B.300d.txt'))\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 512 \n",
    "epochs = 4\n",
    "embed_size = 300 #embeddings dimension\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "print(\"done!\")\n",
    "# importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import re\n",
    "# Fork of Sergei Fironov's script CNN GLOVE300 3-OOF 3 epochs\n",
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '4'\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Embedding, Input, Concatenate, Conv1D, Activation, TimeDistributed, Flatten, RepeatVector, Permute,multiply\n",
    "from keras.layers import LSTM, Bidirectional, GlobalMaxPool1D, Dropout, GRU, GlobalAveragePooling1D, MaxPooling1D, SpatialDropout1D, BatchNormalization\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "list_sentences_train = train[\"text\"].fillna(\"\").values #(30053,)\n",
    "print(list_sentences_train.shape) # print(list_sentences_train.shape) # \n",
    "y = train[\"label\"].values\n",
    "max_features = 150#15500 #\n",
    "maxlen = 7000 #padding length\n",
    "num_folds = 3#2 #number of folds\n",
    "list_sentences_test = test[\"text\"].fillna(\"\").values\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "print('mean text len:',train[\"text\"].str.count('\\S+').mean())\n",
    "print('max text len:',train[\"text\"].str.count('\\S+').max())\n",
    "min_count =2\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(list(list_sentences_train) + list(list_sentences_test))\n",
    "num_words = sum([1 for _, v in tokenizer.word_counts.items() if v >= min_count])\n",
    "print('num_words',num_words)\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(list_sentences_train)) # + list(list_sentences_test)\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\n",
    "list_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)\n",
    "print('padding sequences')\n",
    "X_train = {}\n",
    "X_test = {}\n",
    "X_train['sentence'] = sequence.pad_sequences(list_tokenized_train, maxlen=maxlen, padding='post', truncating='post')\n",
    "X_test['sentence'] = sequence.pad_sequences(list_tokenized_test, maxlen=maxlen, padding='post', truncating='post')\n",
    "\n",
    "print('numerical variables')\n",
    "train['num_words'] = train.sentence.str.count('\\S+')\n",
    "test['num_words'] = test.sentence.str.count('\\S+')\n",
    "\n",
    "rain['avg_word'] = train.sentence.str.len() / (1 + train.num_words)\n",
    "test['avg_word'] = test.sentence.str.len() / (1 + test.num_words)\n",
    "print('sentiment')\n",
    "\n",
    "train['num_comas'] = train.sentence.str.count('\\.')\n",
    "test['num_comas'] = test.sentence.str.count('\\.')\n",
    "train['num_bangs'] = train.sentence.str.count('\\!')\n",
    "test['num_bangs'] = test.sentence.str.count('\\!')\n",
    "train['num_quotas'] = train.sentence.str.count('\\\"')\n",
    "test['num_quotas'] = test.sentence.str.count('\\\"')\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train['num_vars'] = scaler.fit_transform(train[['SentimentScores','num_words','num_comas','num_bangs','num_quotas','avg_word','len', 'qmark', 'SentimentScores', 'Ncommas',\n",
    "       'Nsemicolumns', 'Ncolons', 'Nblank', 'Nother', 'Ncapitalfirst', \n",
    "       'Ncapital', 'Nnumber', 'Nwords', 'Nunique', 'Nrepeated',\n",
    "       'UniquenessRatio', 'Wmean', 'Wmedian', 'Wsd']])\n",
    "\n",
    "X_test['num_vars'] = scaler.transform(test[['SentimentScores','num_words','num_comas','num_bangs','num_quotas','avg_word','len', 'qmark', 'SentimentScores', 'Ncommas',\n",
    "       'Nsemicolumns', 'Ncolons', 'Nblank', 'Nother', 'Ncapitalfirst',\n",
    "       'Ncapital', 'Nnumber', 'Nwords', 'Nunique', 'Nrepeated',\n",
    "       'UniquenessRatio', 'Wmean', 'Wmedian', 'Wsd']])\n",
    "\n",
    "all_embs = np.stack(embeddings_index.values())\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "\n",
    "print('create embedding matrix')\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "\n",
    "def get_model_cnn(X_train):\n",
    "    global embed_size\n",
    "    inp = Input(shape=(maxlen, ), name=\"text\")\n",
    "    num_vars = Input(shape=[X_train[\"num_vars\"].shape[1]], name=\"num_vars\")\n",
    "    x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
    "    x = SpatialDropout1D(0.2)(x)\n",
    "    z = GlobalMaxPool1D()(x)\n",
    "    x = GlobalMaxPool1D()(Conv1D(embed_size, 4, activation=\"relu\")(x))\n",
    "    x = Concatenate()([x,z,num_vars])\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=[inp,num_vars], outputs=x)\n",
    "    model.compile(loss=binary_crossentropy, optimizer='adam', metrics=['accuracy', precision, recall, fmeasure])\n",
    "    return model   \n",
    "\n",
    "print(\"GLOVE KERAS SIMPLE MODEL! WITH FE! 300Dimension Glovee\\n\")\n",
    "print('start modeling')\n",
    "scores = []\n",
    "predict = np.zeros((test.shape[0],1))\n",
    "oof_predict = np.zeros((train.shape[0],1))\n",
    "f1_scores = []\n",
    "acc_scores = []\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=239)\n",
    "for train_index, test_index in kf.split(X_train['num_vars']):\n",
    "    kfold_X_train = {}\n",
    "    kfold_X_valid = {}\n",
    "    y_train,y_test = y[train_index], y[test_index]\n",
    "    for c in ['text','num_vars']:\n",
    "        kfold_X_train[c] = X_train[c][train_index]\n",
    "        kfold_X_valid[c] = X_train[c][test_index]\n",
    "\n",
    "    model = get_model_cnn(X_train)\n",
    "    model.fit(kfold_X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1)\n",
    "    predict += model.predict(X_test, batch_size=1000) / num_folds\n",
    "    oof_predict[test_index] = model.predict(kfold_X_valid, batch_size=1000)\n",
    "    \n",
    "    cv_score = metrics.roc_auc_score(y_test, oof_predict[test_index])\n",
    "    fscore =  f1_score(y_test, oof_predict[test_index])\n",
    "    metrics.average_precision_score(y_test, oof_predict[test_index])\n",
    "    print(model.metrics_names)#, model.metrics_tensors)\n",
    "    scores.append(cv_score)\n",
    "    f1_scores.append(fscore)\n",
    "    print('cv score: ', cv_score)\n",
    "    print('f1 score: ',fscore)\n",
    "    print(classification_report(y_test, oof_predict[test_index]))\n",
    "\n",
    "print('Total CV score is {}'.format(np.mean(scores)))    \n",
    "print('Mean f1 score is {}'.format(np.mean(f1_scores))) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
